import torch
from Faiss import retrieve_text_faiss
from model import generate_answer_fast
import streamlit as st
import time

# Cáº¥u hÃ¬nh giao diá»‡n
st.set_page_config(page_title="Chatbot Luáº­t Giao ThÃ´ng ğŸš¦", page_icon="ğŸš—")

# Hiá»ƒn thá»‹ tiÃªu Ä‘á»
st.markdown(
    "<h1 style='text-align: center; color: #ff5733;'>ğŸš¦ Chatbot Luáº­t Giao ThÃ´ng</h1>",
    unsafe_allow_html=True
)

# Khá»Ÿi táº¡o lá»‹ch sá»­ chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Nháº­n Ä‘áº§u vÃ o tá»« ngÆ°á»i dÃ¹ng
if prompt := st.chat_input("Nháº­p cÃ¢u há»i cá»§a báº¡n táº¡i Ä‘Ã¢y..."):
    # Hiá»ƒn thá»‹ tin nháº¯n ngÆ°á»i dÃ¹ng
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(f"**ğŸ§‘â€ğŸ’¼ Báº¡n:** {prompt}")

    # Xá»­ lÃ½ pháº£n há»“i chatbot
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤– Äang xá»­ lÃ½..."):
            context = retrieve_text_faiss(prompt)
            answer = generate_answer_fast(prompt, context)

        # Hiá»‡u á»©ng gÃµ chá»¯
        full_response = ""
        response_container = st.empty()
        for char in answer:
            full_response += char
            time.sleep(0.02)  # Giáº£ láº­p thá»i gian gÃµ chá»¯
            response_container.markdown(f"**ğŸ¤– Chatbot:** {full_response}")

    # LÆ°u pháº£n há»“i vÃ o lá»‹ch sá»­
    st.session_state.messages.append({"role": "assistant", "content": answer})
